<html>

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Reliable-loc: Robust sequential LiDAR global localization in large-scale street scenes based on verifiable cues</title>
  <link href="./ReliableLoc/style.css" rel="stylesheet">
  <script type="text/javascript" src="./ReliableLoc/jquery.mlens-1.0.min.js"></script>
  <script type="text/javascript" src="./ReliableLoc/jquery.js"></script>
  <style>
    .divider {
      border-right: 2px dashed #737373;
      width: 2px;
    }
  </style>
  <style>
    .divider_horizontal {
      border-top: 2px dashed #737373;
      display: block;
      width: 100%;
      margin: 10px 0;
    }
  </style>
  
</head>

<body>
  <div class="content">
    <h1><strong>Reliable-loc: Robust sequential LiDAR global localization in large-scale street scenes based on verifiable cues</strong>
    </h1>
    <p id="authors">
      <span>
        <a href="https://zouxianghong.github.io/">Xianghong Zou<sup>1</sup></a>
      </span>
      <span>
        <a href="https://github.com/kafeiyin00">Jianping Li<sup>2,&dagger;</sup></a>
      </span>
      <span>
        <a href="https://github.com/wwtinwhu">Weitong Wu<sup>3</sup></a>
      </span>
      <span>
        <a>Fuxun Liang<sup>1</sup></a>
      </span>
      <br>
      <span>
        <a href="https://3s.whu.edu.cn/info/1025/1415.htm">Bisheng Yang<sup>1,&dagger;</sup></a>
      </span>
	  <span>
        <a href="https://dongzhenwhu.github.io/">Zhen Dong<sup>1,4</sup></a>
      </span>
      <br>
      <span class="institution">
        <a href="https://liesmars.whu.edu.cn/"><sup>1</sup> State Key Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University</a><br>
		<a href="https://www.ntu.edu.sg/eee"><sup>2</sup> School of Electrical and Electronic Engineering, Nanyang Technological University</a>
        <a href="https://dlxy.jxnu.edu.cn/"><sup>3</sup> School of Earth Sciences and Engineering, Hohai University</a><br>
		<a href="https://luojia.whu.edu.cn/"><sup>4</sup> Hubei Luojia Laboratory</a><br>
	  </span>  
        <sup>&dagger;</sup>Corresponding authors. &nbsp;&nbsp; 
    </p>
    <font size="+2">
      <p style="text-align: center;">
        <a href="https://arxiv.org/abs/2411.07815" target="_blank">[Paper]</a> &nbsp;&nbsp;&nbsp;&nbsp;
        <!-- <a href="ReliableLoc/Appendix.pdf" target="_blank">[Supp.]</a>&nbsp;&nbsp;&nbsp;&nbsp; -->
        <a href="https://github.com/zouxianghong/Reliable-loc" target="_blank">[Code]</a>&nbsp;&nbsp;&nbsp;&nbsp;
        <a href="ReliableLoc/bibtex.txt" target="_blank">[BibTeX]</a>
      </p>
    </font>
  </div>

  <div class="content">
    <h2 style="text-align:center;">Abstract</h2>
    <p>Wearable laser scanning (WLS) system has the advantages of flexibility and portability. It can be used for determining the user's path within a prior map, which is a huge demand for applications in pedestrian navigation, collaborative mapping, augmented reality, and emergency rescue. However, existing LiDAR-based global localization methods suffer from insufficient robustness, especially in complex large-scale outdoor scenes with insufficient features and incomplete coverage of the prior map. To address such challenges, we propose LiDAR-based reliable global localization (Reliable-loc) exploiting the verifiable cues in the sequential LiDAR data. First, we propose a Monte Carlo Localization (MCL) based on spatially verifiable cues, utilizing the rich information embedded in local features to adjust the particles' weights hence avoiding the particles converging to erroneous regions. Second, we propose a localization status monitoring mechanism guided by the sequential pose uncertainties and adaptively switching the localization mode using the temporal verifiable cues to avoid the crash of the localization system. To validate the proposed Reliable-loc, comprehensive experiments have been conducted on a large-scale heterogeneous point cloud dataset consisting of high-precision vehicle-mounted mobile laser scanning (MLS) point clouds and helmet-mounted WLS point clouds, which cover various street scenes with a length of over 30 km. The experimental results indicate that Reliable-loc exhibits high robustness, accuracy, and efficiency in large-scale, complex street scenes, with a position accuracy of ±2.91 m, yaw accuracy of ±3.74 degrees, and achieves real-time performance.</p>
	<img src="./ReliableLoc/Fig1-Reliable-loc-method-overview.jpg" class="workflow" style="width:100%;"><br>
    <a style="text-align:center">
      Reliable-loc, <strong>based on spatial verification and pose uncertainty</strong>, achieves better robustness in <strong>complex large-scale outdoor scenes with insufficient features and incomplete coverage of the prior map</strong>.
	  1)The spatial verification-based Monte Carlo localization (MCL) adjust particle weights using the rich information embedded in local features. It improves localization robustness in feature-insufficient scenes by avoiding particles converging to erroneous regions.
	  2)The pose uncertainty-based localization status monitor mechanism improves localization robustness in scenes with insufficient features and incomplete map coverage by exploiting the exploratory capability of particles in MCL.
	</a>
  </div>

  <div class="content">
    <h2 style="text-align:center;">Introduction</h2>
    <video width="100%" controls autoplay control src="ReliableLoc/ReliableLoc.mp4" ></video>
    <a href="https://youtu.be/H5IX5K_OVLY" target="_blank">[Youtube]</a>
  </div>

  <div class="content">
    <h2 style="text-align:center;">Experimental Datasets (Self-collected heterogeneous point clouds)</h2>
    <img class="summary-img" src="./ReliableLoc/Fig2-Experiment-data.jpg" style="width:100%;">
    <a>
       Overview of the experimental data: the red and blue lines are the acquisition trajectories of the vehicle-mounted MLS system and the helmet-mounted WLS system respectively (manually offset for display purposes).
    </a>
    <br><br>
	
	<h2 style="text-align:center;">Quantitative evaluation</h2>
	<div>
	  <img class="summary-img" src="./ReliableLoc/Fig3-Quantitative-evaluation-curve.jpg" style="width:100%;">
	</div>
    <a>
      <center>Localization success rate curves of each method on experimental data. (a), (b), (c), (g), (h), (i), (m) are the R@Xm curves, and (d), (e), (f), (j), (k), (l), (n) are the R@Yd curves.</center>
    </a>
	<br>
	
	<div>
	  <div>
	    <img class="summary-img" src="./ReliableLoc/Fig4-Quantitative-evaluation-pva.jpg" style="width:100%;">
	  </div>
	</div>
    <a>
      <center> PVA errors of the proposed method. The black color represents the velocity of the WLS at different time points, while the green, red, and blue colors represent the localization errors of the proposed method at different time points, respectively.</center>
    </a>
	<br>
    <br><br>

    <h2 style="text-align:center;">Analysis and discussion</h2>
	<div>
	  <img class="summary-img" src="./ReliableLoc/Fig5-ablation-SGV-Scoring.jpg" style="width:100%;">
	</div>
    <a>
      <center>Localization trajectories in the four clips when the initial position is known and the yaw is unknown. The black, blue, green, and orange lines are the trajectories of the Ground Truth, PF-loc, PF-SGV-loc, and PF-SGV2-loc, respectively, with the green pentagram as the starting point and the red pentagram as the end point.</center>
    </a>
	<br>
	
	<div>
	  <img class="summary-img" src="./ReliableLoc/Fig6-Loc-mode-switch-necessity.jpg" style="width:100%;">
	</div>
    <a>
      <center>Localization trajectories of Reg-loc and Reliable-loc on four typical scenes. The black, green, and red lines are the trajectories of the Ground Truth, Reg-loc, and Reliable-loc, respectively, with the green pentagram as the starting point and the red pentagram as the end point.</center>
    </a>
	<br><br>
  </div>

  <div class="content">
    <h2>BibTex</h2>
    <code> @article{{zou2025reliableloc,,<br>
  &nbsp;&nbsp;title={Reliable-loc: Robust sequential LiDAR global localization in large-scale street scenes based on verifiable cues},<br>
  &nbsp;&nbsp;author={Xianghong Zou and Jianping Li and Weitong Wu and Fuxun Liang and Bisheng Yang and Zhen Dong},<br>
  &nbsp;&nbsp;journal={ISPRS Journal of Photogrammetry and Remote Sensing},<br>
  &nbsp;&nbsp;volume={224},<br>
  &nbsp;&nbsp;pages={287-301},<br>
  &nbsp;&nbsp;year={2025}<br>
  &nbsp;&nbsp;publisher={Elsevier}<br>
  } </code>
  </div>
  <div class="content" id="acknowledgements">
    <p><strong>Acknowledgements</strong>:
      We borrow this template from <a href="https://whu-usi3dv.github.io/FreeReg/">FreeReg</a>.
    </p>
  </div>
</body>

</html>
